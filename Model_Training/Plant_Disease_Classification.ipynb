{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "ysZw7-u9g14m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFu_IEedahdR"
      },
      "outputs": [],
      "source": [
        "import os                       # for working with files\n",
        "import numpy as np              # for numerical computations\n",
        "import pandas as pd             # for working with dataframes\n",
        "import torch                    # PyTorch module\n",
        "import matplotlib.pyplot as plt # for plotting information on graphs and images using tensors\n",
        "import torch.nn as nn           # for creating neural networks\n",
        "from torch.utils.data import DataLoader # for data loaders\n",
        "from PIL import Image           # for checking images\n",
        "import torch.nn.functional as F # for functions for calculating loss\n",
        "import torchvision.transforms as transforms   # for transforming images into tensors\n",
        "from torchvision.utils import make_grid       # for data checking\n",
        "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
        "from torchsummary import summary              # for getting the summary of our model\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/FYP/Datasets/New Plant Diseases DatasetUpdated)/New Plant Diseases Dataset(Augmented)\"\n",
        "train_dir = data_dir + \"/train\"\n",
        "valid_dir = data_dir + \"/valid\"\n",
        "diseases = os.listdir(train_dir)"
      ],
      "metadata": {
        "id": "Z5h6HPwxy6to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the disease names\n",
        "print(diseases)"
      ],
      "metadata": {
        "id": "-OwZtukiwhJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total disease classes are: {}\".format(len(diseases)))"
      ],
      "metadata": {
        "id": "NMz1EX0-g-nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plants = []\n",
        "NumberOfDiseases = 0\n",
        "for plant in diseases:\n",
        "    if plant.split('___')[0] not in plants:\n",
        "        plants.append(plant.split('___')[0])\n",
        "    if plant.split('___')[1] != 'healthy':\n",
        "        NumberOfDiseases += 1"
      ],
      "metadata": {
        "id": "PUOOdIpMa5fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique plants in the dataset\n",
        "print(f\"Unique Plants are: \\n{plants}\")"
      ],
      "metadata": {
        "id": "njHfz-NTa-dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of unique plants\n",
        "print(\"Number of plants: {}\".format(len(plants)))"
      ],
      "metadata": {
        "id": "YlPK1csSbcVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of unique diseases\n",
        "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
      ],
      "metadata": {
        "id": "bjJxVhShb6lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images for each disease\n",
        "nums = {}\n",
        "for disease in diseases:\n",
        "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
        "\n",
        "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
        "\n",
        "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
        "img_per_class"
      ],
      "metadata": {
        "id": "WOWMViymbFOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the nums dictionary to a pandas dataframe passing index as plant name and number of images as column\n",
        "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
        "img_per_class\n",
        "\n",
        "# Plotting number of images available for each disease\n",
        "index = [n for n in range(19)]\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
        "plt.xlabel('Plants/Diseases', fontsize=10)\n",
        "plt.ylabel('No of images available', fontsize=10)\n",
        "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
        "plt.title('Images per each class of plant disease')"
      ],
      "metadata": {
        "id": "ec2_rYAV36TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting number of images available for each disease\n",
        "index = [n for n in range(19)]\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
        "plt.xlabel('Plants/Diseases', fontsize=10)\n",
        "plt.ylabel('No of images available', fontsize=10)\n",
        "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
        "plt.title('Images per each class of plant disease')"
      ],
      "metadata": {
        "id": "N8L7WZX8i9XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = 0\n",
        "for value in nums.values():\n",
        "    n_train += value\n",
        "print(f\"There are {n_train} images for training\")"
      ],
      "metadata": {
        "id": "bQmNv9Fei_0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets for validation and training\n",
        "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
        "valid = ImageFolder(valid_dir, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "pre0naXjjDdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train[0]\n",
        "print(img.shape, label)"
      ],
      "metadata": {
        "id": "4W2ouYx3jGiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total number of classes in train set\n",
        "len(train.classes)"
      ],
      "metadata": {
        "id": "fjgkODxHjLE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for checking some images from training dataset\n",
        "def show_image(image, label):\n",
        "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
        "    plt.imshow(image.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "9M2xYS0cjOOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(*train[0])"
      ],
      "metadata": {
        "id": "C1r4pHXCjRz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(*train[3000])"
      ],
      "metadata": {
        "id": "-YNGfwLPztns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the seed value\n",
        "random_seed = 7\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Setting the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoaders for training and validation\n",
        "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2)\n",
        "valid_dl = DataLoader(valid, batch_size, num_workers=2)"
      ],
      "metadata": {
        "id": "LbPZhsGlz2DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        return self.relu2(out) + x # ReLU can be applied before or after adding the input\n"
      ],
      "metadata": {
        "id": "yUzMsZQk0iH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For calculating the accuracy\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "# Base class for the model\n",
        "class ImageClassificationBase(nn.Module):\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                   # Generate prediction\n",
        "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
        "        acc = accuracy(out, labels)          # Calculate accuracy\n",
        "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
        "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss\n",
        "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
        "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n"
      ],
      "metadata": {
        "id": "qDbD_Tbj0mTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture for training\n",
        "\n",
        "# Convolution block with BatchNormalization\n",
        "def ConvBlock(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "             nn.BatchNorm2d(out_channels),\n",
        "             nn.ReLU(inplace=True)]\n",
        "    if pool:\n",
        "        layers.append(nn.MaxPool2d(4))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# ResNet architecture\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_diseases):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels, 64)\n",
        "        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64\n",
        "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
        "\n",
        "        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n",
        "        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n",
        "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
        "                                       nn.Flatten(),\n",
        "                                       nn.Linear(512, num_diseases))\n",
        "\n",
        "    def forward(self, xb): # xb is the loaded batch\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "FBYC4hTU0wNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "model = ResNet9(3, len(train.classes))\n",
        "model\n"
      ],
      "metadata": {
        "id": "I7J5u8WW092D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch-xla==1.9\n"
      ],
      "metadata": {
        "id": "Ti3QUdXe5kTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "INPUT_SHAPE = (3, 256, 256)\n",
        "\n",
        "# Create a dummy input tensor on the CPU device\n",
        "dummy_input = torch.randn(1, *INPUT_SHAPE)\n",
        "\n",
        "# Print the model summary\n",
        "print(summary(model, input_size=INPUT_SHAPE))\n"
      ],
      "metadata": {
        "id": "Y1vMRLA55XZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "\n",
        "def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n",
        "                grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "\n",
        "    device = xm.xla_device()  # Use TPU device\n",
        "    model = model.to(device)  # Move model to TPU device\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # scheduler for one cycle learning rate\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            images, labels = batch[0].to(device), batch[1].to(device)  # Move batch to TPU device\n",
        "            loss = model.training_step((images, labels))\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            xm.optimizer_step(optimizer)  # TPU-specific optimizer step\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # recording and updating learning rates\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "\n",
        "        # validation\n",
        "        val_loader = DeviceDataLoader(val_loader, device)  # Move validation data loader to TPU device\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "cP9ZZ0BX6DIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = [evaluate(model, valid_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "Xbi8VF7S6rtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ],
      "metadata": {
        "id": "FXCb2As1Lb6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "epochs = 2\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam\n",
        "\n",
        "history = fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl,\n",
        "                       grad_clip=grad_clip,\n",
        "                       weight_decay=weight_decay,\n",
        "                       opt_func=opt_func)\n",
        "\n",
        "# Record end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the execution time\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time:\", execution_time, \"seconds\")\n"
      ],
      "metadata": {
        "id": "wlRgD7YYLhnd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}