{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3udTGvfyfwq-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["pip install tensorflow keras pandas opencv-python numpy matplotlib seaborn"],"metadata":{"id":"OkztsUlLMtkB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","from keras.models import *\n","from keras.layers import *\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","from keras import optimizers\n","from sklearn.utils import shuffle\n","import seaborn as sns\n","import cv2, os\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Dropout"],"metadata":{"id":"XsrYEl02SA8r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.set_style(\"whitegrid\", {'axes.grid' : False})"],"metadata":{"id":"S5jqa3T9SBr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the path to the dataset folders\n","\n","dir_data=\"/content/drive/MyDrive/FYP/Datasets/Plantsdatasets\"\n","dir_seg = dir_data + \"/images\"\n","dir_img = dir_data + \"/masks/\""],"metadata":{"id":"q4PdStfESDzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_images(data_path, label_path):\n","    data_images = []\n","    label_images = []\n","    for filename in sorted(os.listdir(data_path)):\n","        if filename.endswith('.png'):\n","            # Load data image\n","            data_image = Image.open(os.path.join(data_path, filename)).convert('L')\n","            data_images.append(np.array(data_image))\n","\n","            # Load label image\n","            label_image = Image.open(os.path.join(label_path, filename)).convert('L')\n","            label_images.append(np.array(label_image))\n","    return np.array(data_images), np.array(label_images)\n"],"metadata":{"id":"bL6VQuVe-7tb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir_seg = \"/content/drive/MyDrive/FYP/Datasets/Plantsdatasets/masks\"\n","dir_img = \"/content/drive/MyDrive/FYP/Datasets/Plantsdatasets/images\"\n","\n","# Get the list of files in each directory\n","ldseg = np.array(os.listdir(dir_seg))\n","ldimg = np.array(os.listdir(dir_img))\n","\n","# Pick the first image file\n","fnm = ldseg[0]\n","fnmg = ldimg[0]\n","print(fnm)\n","\n","# Read in the original image and segmentation labels\n","seg = cv2.imread(os.path.join(dir_seg, fnm))\n","img_is = cv2.imread(os.path.join(dir_img, fnmg))\n","\n","if seg is None or img_is is None:\n","    raise FileNotFoundError(\"One or more image files not found.\")\n","\n","print(\"Segmented Image shape:\", seg.shape)\n","print(\"Original Image Shape:\", img_is.shape)\n","\n","# Resize the images to 256x256\n","seg = cv2.resize(seg, (256, 256))\n","img_is = cv2.resize(img_is, (256, 256))\n","\n","print(\"After:\\n\")\n","print(\"Segmented Image shape:\", seg.shape)\n","print(\"Original Image Shape:\", img_is.shape)\n","\n","mi, ma = np.min(seg), np.max(seg)\n","n_classes = 1  # Set to 1 for binary segmentation (one class)\n","print(\"Minimum seg = {}, Maximum seg = {}, Total number of segmentation classes = {}\".format(mi, ma, n_classes))\n","\n","print(\"*****************************\")\n","# Resize the images to 224x224\n","seg = cv2.resize(seg, (224, 224))\n","img_is = cv2.resize(img_is, (224, 224))\n","# Convert to binary format\n","seg = (seg > 0).astype(np.uint8)\n","print(\"Resized seg.shape={},\\nResized img_is.shape={}\".format(seg.shape, img_is.shape))\n"],"metadata":{"id":"Cez59lsL_wgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(5, 5))\n","ax = fig.add_subplot(1, 1, 1)\n","# Assuming img_is is defined somewhere in your code before the plotting\n","\n","ax.imshow(img_is)\n","ax.set_title(\"original image\")\n","plt.show()\n","\n","fig = plt.figure(figsize=(15, 10))\n","for k in range(2):\n","    ax = fig.add_subplot(3, 4, k + 1)\n","    ax.imshow((seg == k) * 1.0)\n","    ax.set_title(\"Segmented Image\\nlabel = {}\".format(k))\n","\n","plt.show()"],"metadata":{"id":"pQ9z8faCXo4S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(5, 5))\n","ax = fig.add_subplot(1, 1, 1)\n","ax.imshow((seg == 1) * 1.0)\n","ax.set_title(\"Segmented Image\\nlabel = 1\")\n","plt.show()\n"],"metadata":{"id":"ycgZ7z-THGZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#this is for coloring the segments\n","def give_color_to_seg_img(seg, n_classes):\n","    if len(seg.shape) == 3:\n","        seg = seg[:, :, 0]\n","    seg_img = np.zeros((seg.shape[0], seg.shape[1], 3)).astype('float')\n","    colors = sns.color_palette(\"hls\", n_classes)\n","\n","    for c in range(n_classes):\n","        segc = (seg == c)\n","        seg_img[:, :, 0] += (segc * (colors[c][0]))\n","        seg_img[:, :, 1] += (segc * (colors[c][1]))\n","        seg_img[:, :, 2] += (segc * (colors[c][2]))\n","\n","    return seg_img\n"],"metadata":{"id":"jSoRgy6ySRbO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_height, input_width = 224, 224\n","output_height, output_width = 224, 224\n","\n","ldseg = np.array(os.listdir(dir_seg))\n","for fnm in ldseg[np.random.choice(len(ldseg), 3, replace=False)]:\n","    fnm = fnm.strip()  # Remove any leading/trailing whitespace\n","    seg_path = os.path.join(dir_seg, fnm)\n","    img_path = os.path.join(dir_img, fnm)\n","\n","    # Check if file paths are valid\n","    if not os.path.exists(seg_path) or not os.path.exists(img_path):\n","        print(f\"File not found: {seg_path} or {img_path}\")\n","        continue\n","\n","    seg = cv2.imread(seg_path)\n","    img_is = cv2.imread(img_path)\n","\n","    # Check if images are read correctly\n","    if seg is None or img_is is None:\n","        print(f\"Failed to read images for {fnm}\")\n","        continue\n","\n","    seg_img = give_color_to_seg_img(seg, n_classes)\n","    #seg = seg.astype(np.uint8)  # Convert seg_img to uint8 dtype\n","    #seg = seg / 255.0  # Normalize seg_img to [0, 1]\n","\n","    fig = plt.figure(figsize=(20, 40))\n","    ax = fig.add_subplot(1, 4, 1)\n","    ax.imshow(seg)\n","\n","    ax = fig.add_subplot(1, 4, 2)\n","    ax.imshow(img_is)\n","    ax.set_title(\"original image {}\".format(img_is.shape[:2]))\n","\n","    ax = fig.add_subplot(1, 4, 3)\n","    ax.imshow(cv2.resize(seg, (output_height, output_width)))\n","\n","    ax = fig.add_subplot(1, 4, 4)\n","    ax.imshow(cv2.resize(img_is, (output_height, output_width)) )\n","    ax.set_title(\"resized to {}\".format((output_height, output_width)))\n","    plt.show()\n"],"metadata":{"id":"hG_8Flq4SYFj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seg_img.shape"],"metadata":{"id":"wpw2J2rzfLlJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","def getImageArr(path, width, height):\n","    img = cv2.imread(path)\n","    img = cv2.resize(img, (width, height))\n","    # Perform any additional preprocessing if needed\n","    return img\n","\n","def getSegmentationArr(path, num_classes, width, height):\n","    seg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","    seg = cv2.resize(seg, (width, height))\n","    seg = (seg > 0).astype(np.uint8)  # Convert to binary format\n","    # Perform any additional preprocessing if needed\n","    return seg\n","\n","\n"],"metadata":{"id":"a6CPUep3gYx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def FCN8(nClasses, input_height=224, input_width=224):\n","    assert input_height % 32 == 0\n","    assert input_width % 32 == 0\n","    IMAGE_ORDERING = \"channels_last\"\n","\n","    img_input = Input(shape=(input_height, input_width, 3))\n","\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING)(img_input)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING)(x)\n","    f1 = x\n","\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING)(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING)(x)\n","    f2 = x\n","\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING)(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING)(x)\n","    pool3 = x\n","\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING)(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n","    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING)(x)\n","\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING)(pool4)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n","    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING)(x)\n","\n","    n = 4096\n","    o = Conv2D(n, (7, 7), activation='relu', padding='same', name=\"conv6\", data_format=IMAGE_ORDERING)(pool5)\n","    conv7 = Conv2D(n, (1, 1), activation='relu', padding='same', name=\"conv7\", data_format=IMAGE_ORDERING)(o)\n","\n","    conv7_4 = Conv2DTranspose(nClasses, kernel_size=(4, 4), strides=(4, 4), use_bias=False, data_format=IMAGE_ORDERING)(conv7)\n","    pool411 = Conv2D(nClasses, (1, 1), activation='relu', padding='same', name=\"pool4_11\", data_format=IMAGE_ORDERING)(pool4)\n","    pool411_2 = Conv2DTranspose(nClasses, kernel_size=(2, 2), strides=(2, 2), use_bias=False, data_format=IMAGE_ORDERING)(pool411)\n","    pool311 = Conv2D(nClasses, (1, 1), activation='relu', padding='same', name=\"pool3_11\", data_format=IMAGE_ORDERING)(pool3)\n","    o = Add(name=\"add\")([pool411_2, pool311, conv7_4])\n","    o = Conv2DTranspose(nClasses, kernel_size=(8, 8), strides=(8, 8), use_bias=False, data_format=IMAGE_ORDERING)(o)\n","    o = Activation('sigmoid')(o)  # Use sigmoid activation for binary segmentation\n","\n","    model = Model(img_input, o)\n","\n","    return model"],"metadata":{"id":"iGkvS0q8TkGK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = FCN8(nClasses=n_classes, input_height=224, input_width=224)"],"metadata":{"id":"Z8G2G0hCTnKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()\n"],"metadata":{"id":"jYPhaG57Trsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images = os.listdir(dir_img)\n","images.sort()\n","segmentations = os.listdir(dir_seg)\n","segmentations.sort()\n","\n","# Initialize empty lists\n","X = []\n","Y = []\n","\n","# Ensure every image has a corresponding segmentation mask\n","for im in images:\n","    corresponding_seg = im  # Assuming filenames match between images and masks\n","    if corresponding_seg in segmentations:\n","        X.append(getImageArr(os.path.join(dir_img, im), input_width, input_height))\n","        Y.append(getSegmentationArr(os.path.join(dir_seg, corresponding_seg), n_classes, output_width, output_height))\n","    else:\n","        print(f\"No corresponding segmentation found for image: {im}\")\n","\n","# Convert to arrays and check lengths\n","X = np.array(X)\n","Y = np.array(Y)\n","\n","if X.shape[0] != Y.shape[0]:\n","    raise ValueError(f\"The number of samples in X and Y do not match: {X.shape[0]} != {Y.shape[0]}\")\n","\n","train_rate = 0.70\n","index_train = np.random.choice(X.shape[0], int(X.shape[0] * train_rate), replace=False)\n","index_test = list(set(range(X.shape[0])) - set(index_train))\n","\n","# Shuffle the data\n","X, Y = shuffle(X, Y)\n","\n","# Split the data\n","X_train, y_train = X[index_train], Y[index_train]\n","X_test, y_test = X[index_test], Y[index_test]\n","\n","print(\"Input Training Shape:\", X_train.shape, \"\\nOutput Training Shape:\", y_train.shape)\n","print(\"Input Testing Shape:\", X_test.shape, \"\\nOutput Testing Shape: \", y_test.shape)"],"metadata":{"id":"hFma0Q1jTweU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the callbacks\n","checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/FYP/Trained Models/best_model.h5\",\n","                             monitor='val_loss',\n","                             verbose=1,\n","                             save_best_only=True,\n","                             save_weights_only=False,\n","                             mode='min',\n","                             save_freq='epoch')\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n"],"metadata":{"id":"sD4On0XVbhK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","sgd = keras.optimizers.Adam(learning_rate=1e-4)\n","model.compile(loss='binary_crossentropy',\n","              optimizer=sgd,\n","              metrics=['accuracy'])"],"metadata":{"id":"FQTciFbpbmQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model with callbacks\n","hist1 = model.fit(X_train, y_train,\n","                  validation_data=(X_test, y_test),\n","                  batch_size=32,\n","                  epochs=100,\n","                  verbose=1,\n","                  callbacks=[checkpoint, early_stopping])"],"metadata":{"id":"MVVoZEznbqQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the entire model including architecture and weights\n","model.save(\"/content/drive/MyDrive/FYP/Trained Models/best_model.h5\")\n"],"metadata":{"id":"b_uO87N6UThg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the best weights\n","model.load_weights(\"/content/drive/MyDrive/FYP/Trained Models/best_model.h5\")"],"metadata":{"id":"HY3MnjbFbwO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","evaluation = model.evaluate(X_test, y_test, verbose=1)\n","print(f\"Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}\")"],"metadata":{"id":"roj8rA8tbzav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot Training and Validation Accuracy\n","plt.plot(hist1.history['accuracy'], label='Training Accuracy')\n","plt.plot(hist1.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"SCXvv-f4VLkO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot Loss\n","plt.subplot(2, 1, 1)\n","plt.plot(hist1.history['loss'], label='Loss')\n","plt.legend()\n","\n","# Plot Accuracy\n","plt.subplot(2, 1, 2)\n","plt.plot(hist1.history['accuracy'], label='Accuracy')\n","plt.legend()\n","\n","plt.show()\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"MBR5y3MOeu2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key in ['loss', 'accuracy']:\n","    plt.plot(hist1.history[key],label=key)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"xODJcxB1WD1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Retrieve the training history\n","training_loss = hist1.history['loss']\n","training_accuracy = hist1.history['accuracy']\n","validation_loss = hist1.history['val_loss']\n","validation_accuracy = hist1.history['val_accuracy']\n","\n","# Plot the training and validation loss\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(training_loss, label='Training Loss')\n","plt.plot(validation_loss, label='Validation Loss')\n","plt.title('Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plot the training and validation accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(training_accuracy, label='Training Accuracy')\n","plt.plot(validation_accuracy, label='Validation Accuracy')\n","plt.title('Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"j7rWL_R6WM9n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(X_test)\n","y_predi = (y_pred > 0.5).astype(np.uint8)  # Apply threshold for binary classification\n","y_testi = (y_test > 0.5).astype(np.uint8)\n","\n","print(y_testi.shape, y_predi.shape)\n"],"metadata":{"id":"OVoI9N7hGGxl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def IoU(Yi, y_predi):\n","    # Mean Intersection over Union\n","    # Mean IoU = TP / (FN + TP + FP)\n","\n","    IoUs = []\n","    Nclass = int(np.max(Yi)) + 1\n","    for c in range(Nclass):\n","        TP = np.sum((Yi == c) & (np.squeeze(y_predi) == c))\n","        FP = np.sum((Yi != c) & (np.squeeze(y_predi) == c))\n","        FN = np.sum((Yi == c) & (np.squeeze(y_predi) != c))\n","        IoU = TP / float(TP + FP + FN)\n","        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c, TP, FP, FN, IoU))\n","        IoUs.append(IoU)\n","    mIoU = np.mean(IoUs)\n","    print(\"_________________\")\n","    print(\"Mean IoU: {:4.3f}\".format(mIoU))\n","\n","# Assuming y_testi and y_predi are the true labels and predicted labels, respectively\n","IoU(y_testi == 1, y_predi == 1)\n"],"metadata":{"id":"Uu2hZZhVGZ1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def IoU(Yi, y_predi):\n","    # Mean Intersection over Union\n","    # Mean IoU = TP / (FN + TP + FP)\n","\n","    IoUs = []\n","    Nclass = int(np.max(Yi)) + 1\n","    for c in range(Nclass):\n","        TP = np.sum((Yi == c) & (np.squeeze(y_predi) == c))\n","        FP = np.sum((Yi != c) & (np.squeeze(y_predi) == c))\n","        FN = np.sum((Yi == c) & (np.squeeze(y_predi) != c))\n","        IoU = TP / float(TP + FP + FN)\n","        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c, TP, FP, FN, IoU))\n","        IoUs.append(IoU)\n","    mIoU = np.mean(IoUs)\n","    print(\"_________________\")\n","    print(\"Mean IoU: {:4.3f}\".format(mIoU))\n","\n","# Assuming y_testi and y_predi are the true labels and predicted labels, respectively\n","IoU(y_testi, y_predi)\n","\n"],"metadata":{"id":"APxr6N0PGeb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","shape = (224, 224)\n","n_classes = 1  # Set to 1 for binary segmentation (one class)\n","\n","for i in range(10):\n","    img_is = (X_test[i]) * (255)\n","    seg = y_predi[i]\n","    segtest = y_testi[i]\n","\n","    # Do not normalize the original image\n","    img_is_normalized = img_is\n","\n","    # Normalize the predicted and true segmentation masks\n","    seg_normalized = (seg == 0).astype(float)\n","    segtest_normalized = (segtest == 0).astype(float)\n","\n","    fig = plt.figure(figsize=(10, 30))\n","    ax = fig.add_subplot(1, 3, 1)\n","    ax.imshow(img_is_normalized)  # Ensure that the image is of 'uint8' type\n","    ax.set_title(\"Original\")\n","\n","    ax = fig.add_subplot(1, 3, 2)\n","    ax.imshow(seg_normalized)\n","    ax.set_title(\"Predicted Class\")\n","\n","    ax = fig.add_subplot(1, 3, 3)\n","    ax.imshow(segtest_normalized)\n","    ax.set_title(\"True Class\")\n","    plt.show()\n"],"metadata":{"id":"W8oKN-K0Gpw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MmsU_FSGgk1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shape = (224, 224)\n","n_classes = 1\n","\n","for i in range(1):\n","    img_is = (X_test[i] ) * (255)\n","    seg = y_predi[i]\n","    segtest = y_testi[i]\n","\n","    # Do not normalize the original image\n","    img_is_normalized = img_is\n","\n","    fig = plt.figure(figsize=(10, 30))\n","    ax = fig.add_subplot(1, 3, 1)\n","    ax.imshow(img_is_normalized)  # Ensure that the image is of 'uint8' type\n","    ax.set_title(\"Original\")\n","\n","    ax = fig.add_subplot(1, 3, 2)\n","    ax.imshow(give_color_to_seg_img(seg, n_classes))\n","    ax.set_title(\"Predicted Class\")\n","\n","    ax = fig.add_subplot(1, 3, 3)\n","    ax.imshow(give_color_to_seg_img(segtest, n_classes))\n","    ax.set_title(\"True Class\")\n","    plt.show()\n"],"metadata":{"id":"U3UnSyedvhEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","# Load the pre-trained model from the H5 file\n","model = keras.models.load_model(\"/content/drive/MyDrive/FYP/Trained Models/DiseasedPlantFCN.h5\")\n","\n","# Load and preprocess a new image for prediction\n","new_image_path = \"/content/drive/MyDrive/FYP/Datasets/images/00010.png\"\n","new_image = cv2.imread(new_image_path)\n","new_image = cv2.resize(new_image, (224, 224))  # Resize the image to match the model's input size\n","new_image = new_image / 255  # Normalize the image to [0, 1]\n","\n","# Convert the image data type to uint8\n","new_image = (new_image * 255).astype(np.uint8)\n","\n","# Expand dimensions to match the model's input shape (add batch dimension)\n","new_image = np.expand_dims(new_image, axis=0)\n","\n","# Make predictions\n","predictions = model.predict(new_image)\n","\n","# Assuming your model outputs binary segmentation\n","binary_predictions = (predictions < 0.5).astype(np.uint8)\n","\n","# Visualize the results\n","fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n","\n","# Display the original image\n","axes[0].imshow(new_image[0])\n","axes[0].set_title(\"Original Image\")\n","\n","# Display the predicted segmentation\n","axes[1].imshow(binary_predictions[0, :, :, 0], cmap=\"gray\")\n","axes[1].set_title(\"Predicted Segmentation\")\n","\n","plt.show()\n"],"metadata":{"id":"guf4vuJiguel"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","# Extract the specific channel (assuming it's the first channel)\n","segmentation_channel = binary_predictions[0, :, :, 0]\n","\n","# Flatten the segmentation channel\n","flat_predictions = segmentation_channel.flatten()\n","\n","# Count the number of pixels with value 1 and 0\n","count_ones = np.sum(flat_predictions == 1)\n","count_zeros = np.sum(flat_predictions == 0)\n","\n","# Calculate the percentage of pixels with value 1 and 0\n","percentage_ones = (count_ones / flat_predictions.size) * 100\n","percentage_zeros = (count_zeros / flat_predictions.size) * 100\n","\n","# Print the results\n","print(f\"Number of pixels with value 1: {count_ones}\")\n","print(f\"Number of pixels with value 0: {count_zeros}\")\n","print(f\"Percentage of pixels with value 1: {percentage_ones:.2f}%\")\n","print(f\"Percentage of pixels with value 0: {percentage_zeros:.2f}%\")\n","\n","print(f\"\\n\\nPlant is infected: {percentage_ones:.2f}%\")"],"metadata":{"id":"PCxd-r5bCBun"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# Load the trained model from the .h5 file\n","model = load_model(\"/content/drive/MyDrive/FYP/Trained Models/DiseasedPlantFCN.h5\")\n","\n","# Evaluate the model on the testing dataset\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n","print(f\"Testing Loss: {test_loss}, Testing Accuracy: {test_accuracy}\")\n","\n","# Evaluate the model on the training dataset\n","train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=1)\n","print(f\"Training Loss: {train_loss}, Training Accuracy: {train_accuracy}\")\n","\n"],"metadata":{"id":"NYeeOBP2k73t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the trained model from the .h5 file\n","model = load_model(\"/content/drive/MyDrive/FYP/Trained Models/best_model.h5\")\n","\n","# Evaluate the model on the testing dataset\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n","print(f\"Testing Loss: {test_loss}, Testing Accuracy: {test_accuracy}\")\n","\n","# Evaluate the model on the training dataset\n","train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=1)\n","print(f\"Training Loss: {train_loss}, Training Accuracy: {train_accuracy}\")\n"],"metadata":{"id":"vviKM2nDl0DR"},"execution_count":null,"outputs":[]}]}