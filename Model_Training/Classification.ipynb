{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1HdsCZ1e1YyLwz384KFJyYKSi9oIG9-Qc","authorship_tag":"ABX9TyMNdxPCHCjHLDiWfsmG13ew"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n"],"metadata":{"id":"Bubyq9B1PJHS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLa_PCHePAx4"},"outputs":[],"source":["# Define constants\n","IMAGE_SIZE = (250, 250)\n","BATCH_SIZE = 32\n","EPOCHS = 10\n","LEARNING_RATE = 0.0001\n"]},{"cell_type":"code","source":["# Function to load images from a directory\n","def load_images_from_folder(folder):\n","    images = []\n","    for filename in os.listdir(folder):\n","        img = cv2.imread(os.path.join(folder, filename))\n","        if img is not None:\n","            img = cv2.resize(img, IMAGE_SIZE)\n","            images.append(img)\n","    return images"],"metadata":{"id":"23N9T2zOQ3EO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load images from folders\n","healthy_images = load_images_from_folder('/content/drive/MyDrive/FYP/Datasets/Plantsdatasets/healthyimages')\n","diseased_images = load_images_from_folder('/content/drive/MyDrive/FYP/Datasets/Plantsdatasets/images')\n"],"metadata":{"id":"I3ceFcqRQ3ON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create labels\n","healthy_labels = [0] * len(healthy_images)\n","diseased_labels = [1] * len(diseased_images)\n","\n","# Combine images and labels\n","X = np.array(healthy_images + diseased_images)\n","y = np.array(healthy_labels + diseased_labels)"],"metadata":{"id":"WJJWxWDERFQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Data normalization\n","X_train = X_train / 255\n","X_test = X_test / 255\n"],"metadata":{"id":"_VhvzdmCRlko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define the model\n","model = Sequential([\n","    Flatten(input_shape=IMAGE_SIZE + (3,)),\n","    Dense(128, activation='relu'),\n","    Dropout(0.3),\n","    Dense(64, activation='relu'),\n","    Dropout(0.3),\n","    Dense(1, activation='sigmoid')\n","])"],"metadata":{"id":"ln3PMb8eRWIV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Print model summary\n","model.summary()"],"metadata":{"id":"fh1oOMB-Yrji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define callbacks for early stopping and model checkpoint\n","callbacks = [\n","    EarlyStopping(patience=3, monitor='val_loss'),\n","    ModelCheckpoint(filepath='best_Classification_model.h5', monitor='val_loss', save_best_only=True)\n","]\n"],"metadata":{"id":"2YDsprDVZ4jR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model with callbacks\n","history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n","                    validation_split=0.1, callbacks=callbacks)"],"metadata":{"id":"cU3--IDzZ_Y6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","accuracy = model.evaluate(X_test, y_test)[1]\n","print(f\"Testing Accuracy: {accuracy*100:.2f}\")\n","\n","Trainaccuracy = model.evaluate(X_train, y_train)[1]\n","print(f\"Training Accuracy: {Trainaccuracy*100:.2f}\")"],"metadata":{"id":"UI6zn2yIYw59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training & validation accuracy values\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()"],"metadata":{"id":"b-l2TVaLamES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the trained model\n","model = load_model('/content/best_Classification_model.h5')  # Path to your trained model\n"],"metadata":{"id":"zrktFtKofs5-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to preprocess image\n","def preprocess_image(image_path):\n","    img = cv2.imread(image_path)\n","    img = cv2.resize(img, (250, 250))\n","    img = img / 255.0  # Normalize the image\n","    return img\n","\n","# Function to make prediction\n","def predict_image(image_path):\n","    img = preprocess_image(image_path)\n","    img = np.expand_dims(img, axis=0)  # Add batch dimension\n","    prediction = model.predict(img)[0][0]  # Get the prediction probability\n","    if prediction >= 0.5:\n","        return \"Diseased\"\n","    else:\n","        return \"Healthy\""],"metadata":{"id":"GMQfQ97Rf07T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Path to the image you want to predict\n","image_path = '/content/drive/MyDrive/FYP/Datasets/Plantsdatasets/healthy/00002.jpg'\n","\n","# Predict the image\n","prediction = predict_image(image_path)\n","print(\"Prediction:\", prediction)\n","\n","# Load and plot the image\n","img = cv2.imread(image_path)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n","plt.imshow(img)\n","plt.axis('off')\n","plt.title(f'Prediction: {prediction}')\n","plt.show()"],"metadata":{"id":"3WJp-3V4f6q8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","\n","# Define source and destination paths\n","source_path = '/content/best_Classification_model.h5'\n","destination_path = '/content/drive/MyDrive/FYP/Trained Models/best_Classification_model.h5'\n","\n","# Move the file to the destination\n","shutil.move(source_path, destination_path)\n","\n","print(f\"File moved from {source_path} to {destination_path}\")\n"],"metadata":{"id":"YlHiJCb6g1th"},"execution_count":null,"outputs":[]}]}