# -*- coding: utf-8 -*-
"""RPDPS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_h9I1HhDhTKMRx0ENmSIbo6AiQxykHtQ
"""

import os
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
import requests
from PIL import Image
from io import BytesIO
import numpy as np
import requests
from io import BytesIO
from keras.preprocessing import image
from google.colab import drive

# Step 1: Mount Google Drive
drive.mount('/content/drive')

# Step 2: Define Data Paths
data_dir = '/content/drive/MyDrive/dataset/resized_raw_images'
train_data_path = '/content/drive/MyDrive/dataset/resized_raw_images/training_data'
validation_data_path = '/content/drive/MyDrive/dataset/resized_raw_images/validation_data'

# function to check images during augmentation
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20, 20))
    axes = axes.flatten()
    for img, ax in zip(images_arr, axes):
        ax.imshow(img)
    plt.tight_layout()
    plt.show()

# Step 3: Data Augmentation and Preprocessing (we will reduce image size to 150,150)
img_size = (150, 150)
batch_size = 32

# Augmentation
training_datagen =  ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    brightness_range=[0.7, 1.3],  # Adjust brightness
    channel_shift_range=50.0,       # Increase or decrease RGB channels
    fill_mode='nearest')

# this is a generator that will read pictures found in
# at train_data_path, and indefinitely generate
# batches of augmented image data
training_data = training_datagen.flow_from_directory(train_data_path, # this is the target directory
                                      target_size=(150, 150), # all images will be resized to 150x150
                                      batch_size=32,
                                      class_mode='sparse')

# determine total number of classes
training_data.class_indices

# rescaling validation images ie normalization
valid_datagen = ImageDataGenerator(rescale=1./255)

# train_generator = train_datagen.flow_from_directory(
#     train_dir,
#     target_size=img_size,
#     batch_size=batch_size,
#     class_mode='sparse'  # Assuming it's a sparse categorical problem
# )

# this is a similar generator, for validation data
valid_data = valid_datagen.flow_from_directory(validation_data_path,
                                  target_size=(150,150),
                                  batch_size=32,
                                  class_mode='sparse')

images = [training_data[0][0][0] for i in range(5)]
plotImages(images)

model_path = '/content/drive/MyDrive/dataset/resized_raw_images/A+_rpdp.h5'
checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# Step 4: Build CNN Model
cnn_model = Sequential([
    Conv2D(filters=32, kernel_size=3, input_shape=(150, 150, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(filters=64, kernel_size=3),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(filters=128, kernel_size=3),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(filters=256, kernel_size=3),
    MaxPooling2D(pool_size=(2, 2)),

    Dropout(0.5),
    Flatten(),
    Dense(units=128, activation='relu'),
    Dropout(0.1),
    Dense(units=256, activation='relu'),
    Dropout(0.25),
    Dense(units=14, activation='softmax')  # Adjusted to 14 classes
])

# cnn_model = Sequential()
# cnn_model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu'))
# cnn_model.add(MaxPooling2D(pool_size=(2, 2)))
# cnn_model.add(Conv2D(64, (3, 3), activation='relu'))
# cnn_model.add(MaxPooling2D(pool_size=(2, 2)))
# cnn_model.add(Flatten())
# cnn_model.add(Dense(64, activation='relu'))
# cnn_model.add(Dense(14, activation='softmax'))

# Compile the model with Adam optimizer, specified learning rate, and sparse categorical crossentropy loss
cnn_model.compile(optimizer=Adam(lr=0.0001),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

cnn_model.summary()

# # Step 5: Callbacks (Early Stopping and Model Checkpoint)
# early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
# model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/best_model.h5',
#                                    monitor='val_accuracy',
#                                    verbose=1,
#                                    save_best_only=True,
#                                    mode='max')  # Save the best model based on validation accuracy

# callbacks_list = [early_stopping, model_checkpoint]

# train cnn model
history = cnn_model.fit(training_data,
                          epochs=500,
                          verbose=1,
                          validation_data= valid_data,
                          callbacks=callbacks_list) # time start 16.06

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns
import numpy as np

# After training the model

# Use the trained model to make predictions on the validation data
y_pred = cnn_model.predict(valid_data)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels

# Get true labels
true_classes = valid_data.classes

# Calculate confusion matrix
conf_matrix = confusion_matrix(true_classes, y_pred_classes)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=valid_data.class_indices.keys(),
            yticklabels=valid_data.class_indices.keys())
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

history.history

# Step 7: Save the Final Model

model_path = '/content/drive/MyDrive/dataset/resized_raw_images/A+_rpdp.h5'
cnn_model.save(model_path)

# Convert the model to TensorFlow Lite format
converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)
tflite_model = converter.convert()

# Save the TensorFlow Lite model to a file
tflite_model_path = '/content/drive/MyDrive/dataset/rpdp.tflite'
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)

#step 9 convert modedl to tflite

# Print the first few labels from training_data
for i in range(5):  # Print the first 5 labels
    print(training_data[i][1])

# Make predictions on validation data
predictions = cnn_model.predict(valid_data)

# predictions will contain the predicted probabilities for each class for each sample
# You can use argmax to get the class with the highest probability as the predicted class
predicted_classes = np.argmax(predictions, axis=1)

# Print some of the predicted classes
print(predicted_classes)

# Load the image
img_path = '/content/drive/MyDrive/dataset/resized_raw_images/validation_data/tungro_virus/Tungro_virus (62).jpg'
img = image.load_img(img_path, target_size=(150, 150))  # Resize the image to 150x150

# Convert the image to a numpy array
img_array = image.img_to_array(img)

# Expand the dimensions to match the input shape expected by the model
img_array = np.expand_dims(img_array, axis=0)  # Shape will be (1, 150, 150, 3) for a single image

# Preprocess the image (e.g., rescaling)
img_array = img_array / 255.0  # Rescale pixel values to [0, 1]

# Make predictions
predictions = cnn_model.predict(img_array)

# Get the predicted class index
predicted_class_index = np.argmax(predictions, axis=1)[0]

# Map the predicted class index to the actual class name
predicted_class = class_names[predicted_class_index]

# Visualize the image
plt.imshow(img)
plt.title(f"Predicted class: {predicted_class}")
plt.axis('off')
plt.show()

# Print the prediction probabilities for each class
print("Prediction Probabilities:")
for class_name, prob in zip(class_names, predictions[0]):
    print(f"{class_name}: {prob:.4f}")

# Assuming you have training_data.class_indices which is a dictionary mapping class names to their indices

# Define the list of class names based on the class indices
class_indices = training_data.class_indices
class_names = list(class_indices.keys())

# URL of the image
url = 'https://soybeanresearchinfo.com/wp-content/uploads/2020/04/SoyFG_Fig076-Bacterial-blight-coalescing-lesion-Daren-Mueller-scaled_1280x720_acf_cropped.jpg'

# Send a GET request to the URL to download the image
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    # Open the image using PIL (Python Imaging Library)
    img = Image.open(BytesIO(response.content))

    # Resize the image to the desired input shape
    img = img.resize((150, 150))  # Resize the image to 150x150

    # Convert the image to a numpy array
    img_array = np.array(img)

    # Expand the dimensions to match the input shape expected by the model
    img_array = np.expand_dims(img_array, axis=0)  # Shape will be (1, 150, 150, 3) for a single image

    # Preprocess the image (e.g., rescaling)
    img_array = img_array / 255.0  # Rescale pixel values to [0, 1]

    # Make predictions
    predictions = cnn_model.predict(img_array)

    # Get the predicted class index
    predicted_class_index = np.argmax(predictions, axis=1)[0]

    # Map the predicted class index to the actual class name
    predicted_class = class_names[predicted_class_index]

    # Print the predicted class
    print("Predicted class:", predicted_class)

    # Dictionary mapping disease classes to categories
    class_to_category = {
        'Rice Blast': 'Fungal',
        'Sheath Blight': 'Fungal',
        'Brown Spot': 'Fungal',
        'Narrow Brown Spot': 'Fungal',
        'Sheath Rot': 'Fungal',
        'Stem Rot': 'Fungal',
        'Bakanae': 'Fungal',
        'Rice False Smut': 'Fungal',
        'Bacterial Leaf Blight': 'Bacterial',
        'Bacterial Leaf Streak': 'Bacterial',
        'Tungro Virus': 'Viral',
        'Ragged Stunt Virus': 'Viral',
        'Grassy Stunt Virus': 'Viral'
    }

    # Get the category based on the predicted disease class
    predicted_category = class_to_category.get(predicted_class, 'Unknown')

    # Print the predicted category
    print("Predicted category:", predicted_category)

    # Print the prediction probabilities for each class
    print("Prediction Probabilities:")
    for class_name, prob in zip(class_names, predictions[0]):
        print(f"{class_name}: {prob:.4f}")
else:
    print("Failed to download the image.")

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np

# Load the saved model
model_path = '/content/drive/MyDrive/dataset/resized_raw_images/A+_rpdp.h5'
loaded_model = load_model(model_path)

# Function to preprocess an image
def preprocess_image(image_path, target_size=(150, 150)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match model input shape
    img_array = img_array / 255.0  # Rescale pixel values
    return img_array

# Function to predict the class of an image
def predict_image_class(image_path, model):
    # Preprocess the image
    img_array = preprocess_image(image_path)

    # Make predictions
    predictions = model.predict(img_array)

    # Get the predicted class index
    predicted_class_index = np.argmax(predictions, axis=1)[0]

    return predicted_class_index

# Provided image path
image_path = '/content/drive/MyDrive/dataset/resized_raw_images/validation_data/tungro_virus/Tungro_virus (62).jpg'

# Predict the class for the image
predicted_class_index = predict_image_class(image_path, loaded_model)
print(f"Predicted Class Index: {predicted_class_index}")

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np

# Load the saved model
model_path = '/content/drive/MyDrive/dataset/resized_raw_images/A+_rpdp.h5'
loaded_model = load_model(model_path)

# Function to preprocess an image
def preprocess_image(image_path, target_size=(150, 150)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match model input shape
    img_array = img_array / 255.0  # Rescale pixel values
    return img_array

# Function to predict the class of an image
def predict_image(image_path, model):
    # Preprocess the image
    img_array = preprocess_image(image_path)

    # Make predictions
    predictions = model.predict(img_array)

    # Get the predicted class index and probability
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    predicted_class_probability = predictions[0][predicted_class_index]

    # Load the class names
    class_names = [
        'bacterial_leaf_blight', 'bacterial_leaf_streak', 'bakanae', 'brown_spot',
        'grassy_stunt_virus', 'healthy_rice_plant', 'narrow_brown_spot',
        'ragged_stunt_virus', 'rice_blast', 'rice_false_smut',
        'sheath_blight', 'sheath_rot', 'stem_rot', 'tungro_virus'
    ]

    # Map the predicted class index to class name
    predicted_class_name = class_names[predicted_class_index]

    # Map the predicted class name to category
    class_to_category = {
        'bacterial_leaf_blight': 'Bacterial',
        'bacterial_leaf_streak': 'Bacterial',
        'bakanae': 'Unknown',
        'brown_spot': 'Fungal',
        'grassy_stunt_virus': 'Viral',
        'healthy_rice_plant': 'Unknown',
        'narrow_brown_spot': 'Fungal',
        'ragged_stunt_virus': 'Viral',
        'rice_blast': 'Fungal',
        'rice_false_smut': 'Fungal',
        'sheath_blight': 'Fungal',
        'sheath_rot': 'Fungal',
        'stem_rot': 'Fungal',
        'tungro_virus': 'Viral'
    }

    predicted_category = class_to_category.get(predicted_class_name, 'Unknown')

    # Print the prediction
    print(f"Predicted Class: {predicted_class_name}")
    print(f"Predicted Category: {predicted_category}")
    print("Prediction Probabilities:")
    for class_name, prob in zip(class_names, predictions[0]):
        print(f"{class_name}: {prob:.4f}")

# Provided image path
# image_path = '/content/drive/MyDrive/dataset/resized_raw_images/validation_data/tungro_virus/Tungro_virus (62).jpg'
image_path = '/content/drive/MyDrive/dataset/resized_raw_images/validation_data/stem_rot/Stem_rot (96).jpeg'

# Predict the class for the image
predict_image(image_path, loaded_model)

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import requests
from PIL import Image
from io import BytesIO

# Load the saved model
model_path = '/content/drive/MyDrive/dataset/resized_raw_images/A+_rpdp.h5'
loaded_model = load_model(model_path)

# Function to preprocess an image
def preprocess_image(img, target_size=(150, 150)):
    img = img.resize(target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match model input shape
    img_array = img_array / 255.0  # Rescale pixel values
    return img_array

# Function to predict the class of an image
def predict_image(image_url, model):
    # Send a GET request to the URL to download the image
    response = requests.get(image_url)

    # Check if the request was successful
    if response.status_code == 200:
        # Open the image using PIL (Python Imaging Library)
        img = Image.open(BytesIO(response.content))

        # Preprocess the image
        img_array = preprocess_image(img)

        # Make predictions
        predictions = model.predict(img_array)

        # Get the predicted class index and probability
        predicted_class_index = np.argmax(predictions, axis=1)[0]
        predicted_class_probability = predictions[0][predicted_class_index]

        # Load the class names
        class_names = [
            'bacterial_leaf_blight', 'bacterial_leaf_streak', 'bakanae', 'brown_spot',
            'grassy_stunt_virus', 'healthy_rice_plant', 'narrow_brown_spot',
            'ragged_stunt_virus', 'rice_blast', 'rice_false_smut',
            'sheath_blight', 'sheath_rot', 'stem_rot', 'tungro_virus'
        ]

        # Map the predicted class index to class name
        predicted_class_name = class_names[predicted_class_index]

        # Map the predicted class name to category
        class_to_category = {
            'bacterial_leaf_blight': 'Bacterial',
            'bacterial_leaf_streak': 'Bacterial',
            'bakanae': 'Fungal',  # Corrected category
            'brown_spot': 'Fungal',
            'grassy_stunt_virus': 'Viral',
            'healthy_rice_plant': 'Unknown',
            'narrow_brown_spot': 'Fungal',
            'ragged_stunt_virus': 'Viral',
            'rice_blast': 'Fungal',
            'rice_false_smut': 'Fungal',
            'sheath_blight': 'Fungal',
            'sheath_rot': 'Fungal',
            'stem_rot': 'Fungal',
            'tungro_virus': 'Viral'
        }

        predicted_category = class_to_category.get(predicted_class_name, 'Unknown')

        # Print the prediction
        print(f"Predicted Class: {predicted_class_name}")
        print(f"Predicted Category: {predicted_category}")
        print("Prediction Probabilities:")
        for class_name, prob in zip(class_names, predictions[0]):
            print(f"{class_name}: {prob:.4f}")
    else:
        print("Failed to download the image.")

# URL of the image from the internet
image_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRACULwDzmhcVKKdE0jA2Rq-IrQeBYp3rwNjw&usqp=CAU'  # Replace with the actual image URL

# Predict the class for the image
predict_image(image_url, loaded_model)

